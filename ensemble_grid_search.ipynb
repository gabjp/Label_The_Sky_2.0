{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "def search(rf_prob, vgg_prob, true):\n",
    "    max = 0\n",
    "    best_i = 0\n",
    "\n",
    "    for i in np.arange(0, 1 + 0.01, 0.01):\n",
    "        ensemble_prob = i * vgg_prob + (1-i)*rf_prob\n",
    "        ensempre_pred = np.argmax(ensemble_prob, axis=1)\n",
    "        score = f1_score(true, ensempre_pred, average='macro')\n",
    "\n",
    "        if score > max:\n",
    "            max = score\n",
    "            best_i = i\n",
    "\n",
    "    print(f\"best i: {best_i}\")\n",
    "\n",
    "    ensemble_prob = best_i * vgg_prob + (1-best_i)*rf_prob\n",
    "    ensempre_pred = np.argmax(ensemble_prob, axis=1)\n",
    "\n",
    "    print(classification_report(true, ensempre_pred, digits = 6, target_names = ['QSO', 'STAR', 'GALAXY']))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(rf_prob, vgg_prob, true, best_i):\n",
    "    ensemble_prob = best_i * vgg_prob + (1-best_i)*rf_prob\n",
    "    ensempre_pred = np.argmax(ensemble_prob, axis=1)\n",
    "\n",
    "    print(classification_report(true, ensempre_pred, digits = 6, target_names = ['QSO', 'STAR', 'GALAXY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## VALIDATION #################################\n",
    "\n",
    "# Performance pairs: 3,2 - 1,3 - 2,1\n",
    "\n",
    "true = np.load('preds/true_nwval.npy')\n",
    "\n",
    "urf1 = np.load('preds/URF_1_nwval.npy')\n",
    "urf2 = np.load('preds/URF_2_nwval.npy')\n",
    "urf3 = np.load('preds/URF_3_nwval.npy')\n",
    "\n",
    "vgg1 = np.load('preds/VGG_1_nwval.npy')\n",
    "vgg2 = np.load('preds/VGG_2_nwval.npy')\n",
    "vgg3 = np.load('preds/VGG_3_nwval.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best i: 0.09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         QSO   0.786408  0.880435  0.830769       276\n",
      "        STAR   0.931389  0.901993  0.916456       602\n",
      "      GALAXY   0.916350  0.870036  0.892593       277\n",
      "\n",
      "    accuracy                       0.889177      1155\n",
      "   macro avg   0.878049  0.884155  0.879939      1155\n",
      "weighted avg   0.893138  0.889177  0.890257      1155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search(urf3, vgg2, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best i: 0.14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         QSO   0.773163  0.876812  0.821732       276\n",
      "        STAR   0.929553  0.898671  0.913851       602\n",
      "      GALAXY   0.919231  0.862816  0.890130       277\n",
      "\n",
      "    accuracy                       0.884848      1155\n",
      "   macro avg   0.873982  0.879433  0.875238      1155\n",
      "weighted avg   0.889706  0.884848  0.886149      1155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search(urf1, vgg3, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best i: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         QSO   0.782178  0.858696  0.818653       276\n",
      "        STAR   0.920068  0.898671  0.909244       602\n",
      "      GALAXY   0.905303  0.862816  0.883549       277\n",
      "\n",
      "    accuracy                       0.880519      1155\n",
      "   macro avg   0.869183  0.873394  0.870482      1155\n",
      "weighted avg   0.883577  0.880519  0.881434      1155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search(urf2, vgg1, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## TEST #################################\n",
    "\n",
    "# Performance pairs: 3,2 - 1,3 - 2,1\n",
    "\n",
    "true = np.load('preds/true_nwtest.npy')\n",
    "\n",
    "urf1 = np.load('preds/URF_1_nwtest.npy')\n",
    "urf2 = np.load('preds/URF_2_nwtest.npy')\n",
    "urf3 = np.load('preds/URF_3_nwtest.npy')\n",
    "\n",
    "vgg1 = np.load('preds/VGG_1_nwtest.npy')\n",
    "vgg2 = np.load('preds/VGG_2_nwtest.npy')\n",
    "vgg3 = np.load('preds/VGG_3_nwtest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         QSO   0.757225  0.864686  0.807396       303\n",
      "        STAR   0.917976  0.844302  0.879599       623\n",
      "      GALAXY   0.859206  0.881481  0.870201       270\n",
      "\n",
      "    accuracy                       0.857860      1196\n",
      "   macro avg   0.844802  0.863490  0.852399      1196\n",
      "weighted avg   0.863983  0.857860  0.859185      1196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval(urf3, vgg2, true, 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         QSO   0.755682  0.877888  0.812214       303\n",
      "        STAR   0.929825  0.850722  0.888516       623\n",
      "      GALAXY   0.879562  0.892593  0.886029       270\n",
      "\n",
      "    accuracy                       0.867057      1196\n",
      "   macro avg   0.855023  0.873734  0.862253      1196\n",
      "weighted avg   0.874360  0.867057  0.868624      1196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval(urf1, vgg3, true, 0.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         QSO   0.776812  0.884488  0.827160       303\n",
      "        STAR   0.928322  0.852327  0.888703       623\n",
      "      GALAXY   0.867384  0.896296  0.881603       270\n",
      "\n",
      "    accuracy                       0.870401      1196\n",
      "   macro avg   0.857506  0.877704  0.865822      1196\n",
      "weighted avg   0.876180  0.870401  0.871509      1196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval(urf2, vgg1, true, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### VALIDATION METRICS ################\n",
    "\n",
    "r1 = [0.889177, 0.879939]\n",
    "r2 = [0.884848, 0.875238]\n",
    "r3 = [0.880519, 0.870482]\n",
    "\n",
    "nw = np.array([r1, r2, r3])*100\n",
    "\n",
    "nw_mean = np.mean(nw, axis=0)\n",
    "nw_std = np.std(nw, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35346137, 0.38608258])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## WITHOUT WISE METRICS ####################\n",
    "\n",
    "r1 = [0.834448, 0.832050]\n",
    "r2 = [0.833612, 0.831975]\n",
    "r3 = [0.832776, 0.830717]\n",
    "\n",
    "nw = np.array([r1, r2, r3])*100\n",
    "\n",
    "nw_mean = np.mean(nw, axis=0)\n",
    "nw_std = np.std(nw, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## UNIFIED RF METRICS ####################\n",
    "\n",
    "r1 = [0.858696 , 0.853476]\n",
    "r2 = [0.859532, 0.853283]\n",
    "r3 = [0.857860 , 0.851644]\n",
    "\n",
    "nw = np.array([r1, r2, r3])*100\n",
    "\n",
    "nw_mean = np.mean(nw, axis=0)\n",
    "nw_std = np.std(nw, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## ENSEMBLE METRICS ####################\n",
    "\n",
    "r1 = [0.857860 ,0.852399]\n",
    "r2 = [0.867057 , 0.862253]\n",
    "r3 = [0.870401 , 0.865822]\n",
    "\n",
    "nw = np.array([r1, r2, r3])*100\n",
    "\n",
    "nw_mean = np.mean(nw, axis=0)\n",
    "nw_std = np.std(nw, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53024504, 0.56766188])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
